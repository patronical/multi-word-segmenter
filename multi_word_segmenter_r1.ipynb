{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Word Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peter Norvig's approach adopted in the code below.  \n",
    "https://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import os\n",
    "import regex as re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "#!pip install -U symspellpy\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity  # import the module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Import Custom Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put dictionary into string\n",
    "with open('custom_dict_bg.txt', 'r') as myfile:\n",
    "    DICT=myfile.read().replace('\\n', '')\n",
    "\n",
    "#add space between numbers and characters\n",
    "DICT2 = re.sub(r'(\\d+)(\\w+)', r'\\1 \\2', DICT.lower())\n",
    "\n",
    "#get list of word and count tuples\n",
    "d_tup = re.findall(r'(\\w+)\\s(\\d+)', DICT2)\n",
    "\n",
    "#assign counter\n",
    "C = Counter()\n",
    "for pair in d_tup:\n",
    "    C[pair[0]] = int(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Implement Word Segmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pword(token):\n",
    "    return (C[token]/30e9)\n",
    "\n",
    "def Pwords(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(Pword(w) for w in words)\n",
    "\n",
    "def product(nums):\n",
    "    \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "    result = 1\n",
    "    for x in nums:\n",
    "        result *= x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    \"Memoize function f, whose args must all be hashable.\"\n",
    "    cache = {}\n",
    "    def fmemo(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = f(*args)\n",
    "        return cache[args]\n",
    "    fmemo.cache = cache\n",
    "    return fmemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(text, start=0, L=20):\n",
    "    \"Return a list of all (first, rest) pairs; start <= len(first) <= L.\"\n",
    "    return [(text[:i], text[i:]) \n",
    "            for i in range(start, min(len(text), L)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordlist(wlist):\n",
    "    wrds = ''\n",
    "    for word in wlist:\n",
    "        wrds += word + ' '\n",
    "    return wrds[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def segment(text):\n",
    "    \"Return a list of words that is the most probable segmentation of text.\"\n",
    "    if not text: \n",
    "        return []\n",
    "    else:\n",
    "        candidates = ([first] + segment(rest) \n",
    "                      for (first, rest) in splits(text, 1))\n",
    "        return max(candidates, key=Pwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_text(text):\n",
    "    return wordlist(segment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_paragraph(text):\n",
    "    pstring = ''\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        pstring += seg_text(token) + ' '\n",
    "    return pstring[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'in', 'the', 'course', 'of', 'human', 'events', 'it', 'becomes', 'necessary', 'for', 'one', 'people', 'to', 'dissolve', 'the', 'political', 'bands', 'which', 'have', 'connected', 'them', 'with', 'another', 'and', 'to', 'assume', 'among', 'the', 'powers', 'of', 'the', 'earth', 'the', 'separate', 'and', 'equal', 'station', 'to', 'which', 'the', 'laws', 'of', 'nature', 'and', 'of', 'natures', 'god', 'entitle', 'them']\n"
     ]
    }
   ],
   "source": [
    "# Peter's example\n",
    "\n",
    "decl = ('wheninthecourseofhumaneventsitbecomesnecessaryforonepeople' +\n",
    "        'todissolvethepoliticalbandswhichhaveconnectedthemwithanother' +\n",
    "        'andtoassumeamongthepowersoftheearththeseparateandequalstation' +\n",
    "        'towhichthelawsofnatureandofnaturesgodentitlethem')\n",
    "\n",
    "print(segment(decl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shri purohit bhagavad gita dnyana mahabaratha pandavas dhritarashtra pandu duryodhana sanjaya bheeshma kurukshetra drona drupada bheema virata soubhadra droupadi karna kuru conches kunti viwaswana manu apana om narada vyasa'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test a long run-on of special words concatenated using the custom dictionary\n",
    "# note this is not intended to make as much sense as Peter's example does above\n",
    "\"\"\"\n",
    "The output we expect:\n",
    "'shri', 'purohit', 'bhagavad', 'gita', 'dnyana', 'mahabaratha', 'pandavas', 'dhritarashtra', 'pandu', \n",
    "'duryodhana', 'sanjaya', 'bheeshma', 'kurukshetra', 'drona', 'drupada', 'bheema', 'virata', 'soubhadra', \n",
    "'droupadi', 'karna', 'kuru', 'conches', 'kunti', 'viwaswana', 'manu', 'knowest', 'apana', 'om', 'narada', \n",
    "'vyasa'\n",
    "\"\"\"\n",
    "seg_text('shripurohitbhagavadgitadnyanamahabarathapandavasdhritarashtrapanduduryodhanasanjayabheeshmakurukshetradronadrupadabheemaviratasoubhadradroupadikarnakuruconcheskuntiviwaswanamanuapanaomnaradavyasa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
